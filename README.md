# PyTorch Implementation of SSTN for Hyperspectral Image Classification

Paper links: [SSTN accepted by IEEE T-GRS](https://www.researchgate.net/publication/355117935_Spectral-Spatial_Transformer_Network_for_Hyperspectral_Image_Classification_A_Factorized_Architecture_Search_Framework).

Code download link: [SSTN code](https://github.com/zilongzhong/SSTN/archive/refs/heads/main.zip).

Here is the bibliography info:

<br/>

```jason
Zilong Zhong, Ying Li, Lingfei Ma, Jonathan Li, Wei-Shi Zheng. "Spectral-Spatial Transformer 
Network for Hyperspectral Image Classification: A Factorized Architecture Search Framework.‚Äù 
IEEE Transactions on Geoscience and Remote Sensing, DOI:10.1109/TGRS.2021.3115699,2021.
```
## Description
Neural networks have dominated the research of hyperspectral image classification, attributing to the feature learning capacity of convolution operations. However, the fixed geometric structure of convolution kernels hinders long-range interaction between features from distant locations.  In this work, we propose a novel spectral-spatial transformer network (SSTN), which consists of spatial attention and spectral association modules, to overcome the constraints of convolution kernels. Extensive experiments conducted on five popular hyperspectral image benchmarks demonstrate the versatility of SSTNs over other state-of-the-art (SOTA) methods. 

<img src="fig_sstn.png" height="400"/>

Fig.1 Spectral-Spatial Transformer Network with the architecture of 'AEAE', in which 'A' and 'E' stand for a spatial attention block and a spectral association block, respectively. (a) Search space for unit setting. (b) Search space for block sequence.

## Prerequisites

## Usage

## Result of Pavia Center (PC) Dataset 

## Result of Indian Pines (IN) dataset

## Result of University of Pavia (UP) dataset



